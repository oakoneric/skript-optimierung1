\section{Dualität}

Wir betrachten nun die Optimierungsaufgabe
\begin{equation*}
	\begin{aligned}
		\qquad &\trans{c} x \to \min \bei Ax \le b \und x \in \Rn_+ \\
		&I \defeq \menge{1, \dots, m} \und J \defeq \menge{1, \dots, n}
	\end{aligned} \tag{P}
	% \label{eq: 3.11}
	\label{eq: P}
\end{equation*}

\begin{satz}[Charakterisierungssatz] %3.9
	\label{satz: 3.9}
	Ein Punkt $x \in \Rn$ ist genau dann Lösung von (P), wenn ein $\quer{u} \in \Rm$ existiert, sodass insgesamt das folgende System gelöst wird:
	\begin{equation*}
		\begin{alignedat}{3}
			A \quer{x} - b &\le 0 \quad &\quer{x} &\ge 0 \qquad \qquad &(1) \\
			\trans{A} \quer{u} + c &\ge 0 \quad &\quer{u} &\ge 0 &(2) \\
			\trans{\quer{u}} \brackets{A \quer{x} - b} &= 0 \qquad \qquad &\trans{\quer{x}} \brackets{\trans{A}\quer{u} + c} &= 0 &(3)
		\end{alignedat}
	\end{equation*}
\end{satz}
\begin{proof}
	Die vorliegende Optimierungsaufgabe ist äquivalent zu
	\begin{equation*}
		f(x) = \trans{c} x \to \min \bei \underbrace{\begin{pmatrix} A \\ - \one_n \end{pmatrix}}_{= \schlange{A} \in \R^{(m + n) \times n}} x \le \underbrace{\begin{pmatrix} b \\ 0 \end{pmatrix}}_{= \schlange{b} \in \R^{m+n}}
		\tag{P'}
		\label{eq: P'}
	\end{equation*}
	Gemäß \cref{lemma: 2.8} ist $x$ genau dann Lösung von \eqref{eq: P'} (und \eqref{eq: P}), wenn ein Vektor $w = \left( \begin{smallmatrix} u \\ v \end{smallmatrix} \right) \in \R^{m + n}$ existiert mit 
	\begin{equation*}
		\begin{alignedat}{2}
			\nabla f(x) + \sum_{i \in I \cup J} w_i \schlange{a}_i &= 0 \\
			w_i &\ge 0 \qquad \qquad &&(i \in I \cup J) \\
			\trans{\schlange{a}_i} x - \schlange{b}_i &\le 0 &&(i \in I \cup J) \\
			w_i \brackets{\trans{\schlange{a}_i} x - b_i} &= 0 &&(i \in I \cup J)
		\end{alignedat}
		\tag{KKT}
	\end{equation*}
	Trennung von $I$ und $J$ führt zu
	\begin{equation*}
		c + \sum_{i \in I} u_i a_i + \sum_{j \in J} v_j (-e^j) = 0
		\tag{KKT}
	\end{equation*}
	\begin{equation*}
		\begin{alignedat}{4}
			u_i &\ge 0 \qquad &&(i \in I) 											& v_j &\ge 0 \qquad &&(j \in J) \\
			\trans{a_i} x - b_i &\le 0 &&(i \in I) 									& \transpose{-e^j} x - 0 &\le 0 &&(j \in J) \\
			u_i \brackets{\trans{a_i} x - b_i} &= 0 &&(i \in I) \qquad\quad	& v_j \brackets{\transpose{-e^j} x - 0} &= 0 &&(j \in J)  \\
		\end{alignedat}
	\end{equation*}
	Überführt man dieses System in eine Matrix-Vektor-Schreibweise, so ergibt sich
	\begin{equation*}
		\begin{aligned}
			c + \trans{A} u - v &= 0 \\
			u,v,x &\ge 0 \\
			Ax - b &\le 0 \\
			\trans{u} \brackets{Ax - b} &= 0 \\
			\trans{x} v &= 0
		\end{aligned}
	\end{equation*}
	Durch Umstellen der ersten Gleichung nach $v$ lässt sich diese Variable im System ''eliminieren`` und wir erhalten die Behauptung.
\end{proof}

\begin{definition} %3.3
	Das Problem
	\begin{equation}
		\text{(D)} \qquad z_D = -\trans{b} u \to \max \quad \bei \quad \trans{A} u \ge -c, \enskip u \in \R_+^m 
		\label{eq: 3.12}
	\end{equation}
	heißt duale Optimierungsaufgabe zu (P).
\end{definition}

\textbf{Begründung:} Die Anwendung von \cref{satz: 3.9} auf (D) ergibt das selbe KKT-System wie im Falle von (P). Dazu müssen wir (D) umformulieren als Minimierungsaufgabe
\begin{equation*}
	- z_D = \trans{b} u \to \min \quad \bei \quad -\trans{A} u \le c, \enskip u \in \R_+^m
\end{equation*}
(damit die selbe Form wie in \cref{satz: 3.9} vorliegt).
Einsetzen in (1) - (3) ergibt
\begin{equation*}
	\begin{alignedat}{3}
		\text{(1)} &\leadsto &-\trans{A} u - c &\le 0, \enskip &u &\ge 0 \\
		\text{(2)} &\leadsto &\transpose{-\trans{A}} y + b &\ge 0, \enskip &y &\ge 0 \\
		\text{(3)} &\leadsto \quad &\trans{y} \brackets{-\trans{A} u - c} &= 0, \quad &\trans{u} \brackets{\transpose{-\trans{A}} y + b} &= 0
	\end{alignedat}
\end{equation*}
Umformulierung liefert
\begin{equation*}
	\begin{alignedat}{4}
		\text{(1)} &\leadsto &\trans{A} u +  c &\ge 0, \enskip &u &\ge 0 \qquad &&\text{entspricht (2) aus System für (P)} \\
		\text{(2)} &\leadsto &Ay - b &\le 0, &y &\ge 0 \qquad &&\text{entspricht (1) aus System für (P) mit $y = x$} \\
		\text{(3)} &\leadsto \quad &\trans{y} \brackets{\trans{A} u + c} &= 0, \quad &\trans{u} \brackets{Ay - b} &= 0 \qquad &&\text{entspricht (3) aus System für (P)}
	\end{alignedat}
\end{equation*}
(D) liefert also dasselbe System (1) - (3) wie (P).

\begin{satz}[schwache Dualität] %3.10
	Sei $x$ zulässig für (P) und $u$ zulässig für (D). Dann gilt
	\begin{equation*}
		-\trans{b} u \le \trans{c} x
	\end{equation*}
\end{satz}
\begin{proof}
	Es gilt
	\begin{align*}
		-\trans{b} u &\le \transpose{-Ax} u = - \trans{x} \trans{A} u \tag{$Ax \le b, u \ge 0$} \\
		&\le \trans{x} c = \trans{c} x \tag{$\trans{A} u \ge -c, x \ge 0$}
	\end{align*}
\end{proof}

\begin{satz}[starke Dualität] %3.11
	Die Optimierungsaufgabe (P) ist genau dann lösbar, wenn (D) lösbar ist. Für die zugehörigen Lösungen $\quer{x}$ und $\quer{u}$ gilt dann
	\begin{equation*}
		- \trans{b} \quer{u} = \trans{c} \quer{x}
	\end{equation*}
	also die Gleichheit der Optimalwerte.
\end{satz}
\begin{proof}
	Der erste Teil der Aussage folgt direkt aus der Gleichheit der KKT-Systeme. Aus Eigenschaft (3) des KKT-Systems folgt dann die Gleichheit der Optimalwerte mittels
	\begin{equation*}
		\trans{\quer{u}} \brackets{A \quer{x} - b} = 0 = \trans{\quer{x}} \brackets{\trans{A} \quer{u} + c} \follows - \trans{b} \quer{u} = \trans{\quer{u}} A \quer{x} = \trans{c} \quer{x}
	\end{equation*}
\end{proof}

Aus dem schwachen Dualitätssatz folgt insbesondere auch, dass die Existenz eines dual (primal) zulässigen Punktes eine endliche untere (obere) Schranke für den primalen (dualen) Optimalwert liefert.

\begin{folgerung} %3.12
	\begin{equation*}
		\text{(P) lösbar } \equivalent \text{ (D) lösbar } \equivalent \exists \ x \ge 0, u \ge 0 \colon Ax \le b, \trans{A} u \ge -c
	\end{equation*}
\end{folgerung}

Die Bedingungen (3) im KKT-System werden \begriff{Komplementaritätsbedingungen} genannt.

zum Beispiel: $\trans{u} \brackets{Ax - b} = 0, x \ge 0, u \ge 0,  Ax - b \le 0$, d.h. $u_i (Ax - b)_i = 0$ für alle $i$.

Es ist möglich, primale und duale Aufgabe gleichzeitig innerhalb eines Tableaus zu lösen:
\begin{equation*}
	\begin{alignedat}{4}
		(P) \quad &z_P &=   \trans{c} x \to \min \quad  &\bei \quad          A x &\le b, &x &\ge 0 \\
		(D) \quad &z_D &= - \trans{b} u \to \max \quad &\bei \quad - \trans{A} u &\le c, &u &\ge 0
	\end{alignedat}
\end{equation*}
Durch Einführen von Schlupfvariablen $s \ge 0$, $v \ge0$ erhält man
\begin{equation*}
	\begin{alignedat}{5}
		(P) \quad &   z_P &= \trans{c} x \to \min \quad &\bei \quad &s &= b - Ax, &x &\ge 0, &s &\ge 0 \\
		(D) \quad & - z_D &= \trans{b} u \to \min \quad &\bei \quad &v &= c + \trans{A} u, &u &\ge 0, &v &\ge 0
	\end{alignedat}
\end{equation*}

\begin{center}
	\begin{tabular}{r|c|c}
		$T_0$ & $x$ & $1$ \\ \hline
		$s = $ & $-A$ & $b$ \\ \hline
		$z_P =$ & $\trans{c}$ & $0$
	\end{tabular}
    $\quad$ bzw. $\quad$
	\begin{tabular}{r|c|c}
		$T_0$ & $u$ & $1$ \\ \hline
		$v = $ & $\trans{A}$ & $c$ \\ \hline
		$- z_D =$ & $\trans{b}$ & $0$
	\end{tabular}
\end{center}

Beide Schemata sind (gewissermaßen) zueinander transponiert.
Das duale Simplexverfahren für (P) kann als primales Simplexverfahrens für (D) interpretiert werden.